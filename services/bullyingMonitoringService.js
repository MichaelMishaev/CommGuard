// services/bullyingMonitoringService.js
// Bullying detection and monitoring service

const { ALL_OFFENSIVE_WORDS } = require('./offensiveWordsDatabase');
const { decodeLIDToPhone } = require('../utils/jidUtils');
const offensiveMessageService = require('../database/offensiveMessageService');
const { getTimestamp } = require('../utils/logger');
const sentimentAnalysisService = require('./sentimentAnalysisService');

class BullyingMonitoringService {
    constructor() {
        this.adminPhone = '972544345287';
        console.log(`[${getTimestamp()}] ğŸ›¡ï¸  Bullying Monitoring Service initialized`);
        console.log(`[${getTimestamp()}] ğŸ“Š Monitoring ${ALL_OFFENSIVE_WORDS.length} offensive words`);
    }

    /**
     * Check if message is discussing fictional content (movies, books, games, etc.)
     * These contexts should be excluded from bullying detection
     * @param {string} messageText - Message to check
     * @returns {boolean} True if discussing fictional content
     */
    isFictionalContext(messageText) {
        if (!messageText || typeof messageText !== 'string') {
            return false;
        }

        const lowerText = messageText.toLowerCase();

        // Hebrew keywords for fictional content
        const hebrewKeywords = [
            '×¡×¨×˜', '×”×¡×¨×˜', '×¡×¨×˜×™×',           // movie, the movie, movies
            '×¡×¤×¨', '×”×¡×¤×¨', '×¡×¤×¨×™×',           // book, the book, books
            '××©×—×§', '×”××©×—×§', '××©×—×§×™×',        // game, the game, games
            '×¡×“×¨×”', '×”×¡×“×¨×”', '×¡×“×¨×•×ª',         // series, the series
            '×ª×•×›× ×™×ª', '×”×ª×•×›× ×™×ª',              // program, the program
            '×“××•×ª', '×”×“××•×ª', '×“××•×™×•×ª',        // character, the character, characters
            '×’×™×‘×•×¨', '×”×’×™×‘×•×¨', '×’×™×‘×•×¨×™×',     // hero, the hero, heroes
            '× ×‘×œ', '×”× ×‘×œ',                    // villain, the villain
            '×©×—×§×Ÿ', '×”×©×—×§×Ÿ', '×©×—×§× ×™×',        // actor, the actor, actors
            '×‘×××™', '×”×‘×××™',                  // director, the director
            '×¢×œ×™×œ×”', '×”×¢×œ×™×œ×”',                // plot, the plot
            '×¤×¨×§', '×”×¤×¨×§', '×¤×¨×§×™×',           // episode, the episode, episodes
            '×¢×•× ×”', '×”×¢×•× ×”',                  // season, the season
            '×× ×™××”', '×”×× ×™××”',                // anime, the anime
            '×§×•××™×§×¡', '×”×§×•××™×§×¡'               // comics, the comics
        ];

        // English keywords for fictional content
        const englishKeywords = [
            'movie', 'film', 'the movie', 'the film',
            'book', 'the book', 'novel', 'the novel',
            'game', 'the game', 'video game',
            'series', 'tv series', 'tv show', 'show',
            'character', 'the character', 'main character',
            'protagonist', 'antagonist', 'villain',
            'actor', 'actress', 'director',
            'plot', 'storyline', 'episode', 'season',
            'anime', 'manga', 'comic', 'comics'
        ];

        // Check for any fictional content keywords
        const allKeywords = [...hebrewKeywords, ...englishKeywords];

        for (const keyword of allKeywords) {
            if (lowerText.includes(keyword)) {
                return true;
            }
        }

        return false;
    }

    /**
     * Check if message contains offensive content
     * @param {string} messageText - Message to analyze
     * @returns {object} { isOffensive: boolean, matchedWords: string[], severity: string }
     */
    checkMessage(messageText) {
        if (!messageText || typeof messageText !== 'string') {
            return {
                isOffensive: false,
                matchedWords: [],
                severity: 'none'
            };
        }

        // NOTE: Removed aggressive pre-filter for fictional content
        // Reason: Caused false negatives like "×¨××™×ª×™ ×¡×¨×˜, ×•××ª×” ×‘×Ÿ ×–×•× ×”" (targeting real person)
        // GPT is smart enough to distinguish fictional vs real context
        // Trade-off: Small cost increase (~$0.0006/message) for 100% accuracy

        // Normalize text: lowercase, remove nikud (Hebrew vowel points)
        const normalizedText = messageText.toLowerCase()
            .replace(/['\u0591-\u05C7]/g, ''); // Remove Hebrew nikud/diacritics

        const matchedWords = [];

        for (const word of ALL_OFFENSIVE_WORDS) {
            const normalizedWord = word.toLowerCase();

            // Create word boundary regex
            // For Hebrew: match the word anywhere in the text
            // For English: require word boundaries
            const isHebrew = /[\u0590-\u05FF]/.test(word);

            let regex;
            if (isHebrew) {
                // Hebrew: match word as substring (Hebrew doesn't have clear word boundaries)
                regex = new RegExp(this.escapeRegex(normalizedWord), 'i');
            } else {
                // English: require word boundaries
                regex = new RegExp(`\\b${this.escapeRegex(normalizedWord)}\\b`, 'i');
            }

            if (regex.test(normalizedText)) {
                matchedWords.push(word);
            }
        }

        // Determine severity based on number of matches
        let severity = 'none';
        if (matchedWords.length >= 3) {
            severity = 'severe';
        } else if (matchedWords.length >= 2) {
            severity = 'moderate';
        } else if (matchedWords.length >= 1) {
            severity = 'mild';
        }

        return {
            isOffensive: matchedWords.length > 0,
            matchedWords,
            severity
        };
    }

    /**
     * Escape special regex characters
     * @param {string} string - String to escape
     * @returns {string} Escaped string
     */
    escapeRegex(string) {
        return string.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
    }

    /**
     * Send alert to admin about offensive content
     * @param {object} sock - WhatsApp socket
     * @param {object} alertData - Alert information
     * @returns {Promise<boolean>} Success status
     */
    async sendAlert(sock, alertData) {
        const {
            groupName,
            groupId,
            senderPhone,
            senderName,
            senderJid,
            messageText,
            matchedWords,
            timestamp,
            severity,
            messageId,
            originalMessage
        } = alertData;

        // Extract real phone number (decode LID if needed)
        let realPhone = senderPhone;
        if (senderJid && senderJid.includes('@lid')) {
            try {
                const decoded = await decodeLIDToPhone(sock, senderJid);
                if (decoded) {
                    realPhone = decoded;
                }
            } catch (error) {
                console.error(`[${getTimestamp()}] âš ï¸  Failed to decode LID:`, error.message);
            }
        }

        // Format severity icon
        const severityIcons = {
            severe: 'ğŸ”´',
            moderate: 'ğŸŸ¡',
            mild: 'ğŸŸ¢'
        };
        const severityIcon = severityIcons[severity] || 'âš ï¸';

        // Format base alert message
        let alertMessage = `${severityIcon} *BULLYING ALERT* ${severityIcon}\n\n` +
            `ğŸ“Š Severity: ${severity.toUpperCase()}\n` +
            `ğŸ‘¥ Group: ${groupName}\n` +
            `ğŸ“± User: ${senderName || 'Unknown'}\n` +
            `ğŸ“ Phone: ${realPhone}\n` +
            `â° Time: ${new Date(timestamp).toLocaleString('he-IL', {
                timeZone: 'Asia/Jerusalem',
                day: '2-digit',
                month: '2-digit',
                year: 'numeric',
                hour: '2-digit',
                minute: '2-digit'
            }).replace(',', '')}\n\n` +
            `ğŸ’¬ Message:\n"${messageText}"\n\n` +
            `âš ï¸  Matched words (${matchedWords.length}): ${matchedWords.join(', ')}`;

        // Store GPT analysis for database saving
        let gptAnalysisData = null;

        // Retrieve conversation context (last 5 messages) for better accuracy
        let conversationContext = [];
        try {
            const CONFIG = require('./sentimentAnalysisConfig');
            const { getRedis } = require('./redisService');
            const redis = getRedis();
            const contextKey = `${CONFIG.REDIS_KEY_CONTEXT}:${groupId}`;

            // Get last 5 messages (excluding current one)
            const contextData = await redis.lrange(contextKey, 1, 5);

            // Parse and VALIDATE context messages (SECURITY: prevent injection)
            conversationContext = contextData.map(data => {
                try {
                    const parsed = JSON.parse(data);

                    // SECURITY: Validate structure and types
                    if (!parsed || typeof parsed !== 'object') {
                        console.warn(`[${getTimestamp()}] âš ï¸  Invalid context: not an object`);
                        return null;
                    }

                    if (!parsed.sender || typeof parsed.sender !== 'string') {
                        console.warn(`[${getTimestamp()}] âš ï¸  Invalid context: missing/invalid sender`);
                        return null;
                    }

                    if (!parsed.text || typeof parsed.text !== 'string') {
                        console.warn(`[${getTimestamp()}] âš ï¸  Invalid context: missing/invalid text`);
                        return null;
                    }

                    if (!parsed.timestamp || typeof parsed.timestamp !== 'number') {
                        console.warn(`[${getTimestamp()}] âš ï¸  Invalid context: missing/invalid timestamp`);
                        return null;
                    }

                    // SECURITY: Validate timestamp is recent (prevent old/fake data)
                    const age = Date.now() - parsed.timestamp;
                    if (age < 0 || age > 3600000) { // Max 1 hour old
                        console.warn(`[${getTimestamp()}] âš ï¸  Invalid context: timestamp out of range (${Math.floor(age / 1000)}s old)`);
                        return null;
                    }

                    // SECURITY: Validate text length (prevent abuse)
                    if (parsed.text.length > 1000) {
                        console.warn(`[${getTimestamp()}] âš ï¸  Invalid context: text too long (${parsed.text.length} chars)`);
                        return null;
                    }

                    return parsed;
                } catch (e) {
                    console.warn(`[${getTimestamp()}] âš ï¸  Failed to parse context message:`, e.message);
                    return null;
                }
            }).filter(Boolean);

            if (conversationContext.length > 0) {
                console.log(`[${getTimestamp()}] ğŸ’¬ Retrieved ${conversationContext.length} validated context messages for GPT analysis`);
            }
        } catch (error) {
            console.error(`[${getTimestamp()}] âš ï¸  Failed to retrieve context:`, error.message);
            // Continue without context (graceful degradation)
        }

        // GPT Sentiment Analysis (with conversation context)
        try {
            const analysis = await sentimentAnalysisService.analyzeMessage(
                messageText,
                matchedWords,
                senderName,
                groupName,
                conversationContext // Pass last 5 messages for context
            );

            if (analysis.analyzed) {
                // Store for database
                gptAnalysisData = {
                    analyzed: true,
                    severity: analysis.severity,
                    confidence: analysis.confidence,
                    category: analysis.category,
                    explanation: analysis.explanation,
                    emotionalImpact: analysis.emotionalImpact,
                    recommendation: analysis.recommendation,
                    cost: analysis.cost
                };

                // Add GPT analysis to alert
                const confidenceEmoji = analysis.confidence >= 80 ? 'ğŸ”´' :
                                       analysis.confidence >= 60 ? 'ğŸŸ¡' : 'ğŸŸ¢';

                alertMessage += `\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n` +
                    `ğŸ§  *AI SENTIMENT ANALYSIS*\n` +
                    `${confidenceEmoji} Confidence: ${analysis.confidence}%\n` +
                    `ğŸ“Š Category: ${analysis.category.replace(/_/g, ' ')}\n` +
                    `ğŸ’­ Analysis: ${analysis.explanation}\n` +
                    `ğŸ’” Impact: ${analysis.emotionalImpact}\n` +
                    `âš¡ Recommendation: ${analysis.recommendation.replace(/_/g, ' ').toUpperCase()}\n\n` +
                    `ğŸ’° Cost: $${analysis.cost.toFixed(6)} | Budget: $${analysis.budgetInfo.remaining.toFixed(4)} left`;

            } else if (analysis.reason === 'Daily budget reached') {
                // Send budget exhausted alert
                await sentimentAnalysisService.sendBudgetAlert(sock);
            }
        } catch (error) {
            console.error(`[${getTimestamp()}] âš ï¸  GPT analysis failed:`, error.message);
            // Continue with basic alert
        }

        // Add action options
        alertMessage += `\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n` +
            `Actions:\n` +
            `â€¢ Reply with 'd' to delete this message\n` +
            `â€¢ Reply with #kick to remove user\n` +
            `â€¢ Send #bullywatch off to disable monitoring\n` +
            `â€¢ Or ignore this message`;

        // Save to database
        try {
            await offensiveMessageService.saveOffensiveMessage({
                messageId,
                whatsappGroupId: groupId,
                groupName,
                senderPhone: realPhone,
                senderName,
                senderJid,
                messageText,
                matchedWords,
                gptAnalysis: gptAnalysisData
            });
        } catch (error) {
            console.error(`[${getTimestamp()}] âš ï¸  Failed to save offensive message to DB:`, error.message);
            // Continue with alert even if DB save fails
        }

        const adminJid = `${this.adminPhone}@s.whatsapp.net`;

        try {
            // Send as quoted reply to original message (so admin can reply with 'd' to delete)
            const quotedMessage = originalMessage ? { quoted: originalMessage } : {};

            const sentMessage = await sock.sendMessage(adminJid, {
                text: alertMessage
            }, quotedMessage);

            // Store mapping of alert message ID â†’ original message ID for delete functionality
            // This allows admin to reply 'd' to the alert to delete the original offensive message
            if (sentMessage && sentMessage.key && sentMessage.key.id && messageId) {
                try {
                    const { getRedis } = require('./redisService');
                    const redis = getRedis();

                    // Store mapping for 24 hours (messages older than this can't be deleted)
                    await redis.setex(
                        `${CONFIG.REDIS_KEY_ALERT_MAP}:${sentMessage.key.id}`,
                        CONFIG.ALERT_MAPPING_TTL_SECONDS,
                        messageId
                    );

                    console.log(`[${getTimestamp()}] ğŸ”— Stored alert mapping: ${sentMessage.key.id} â†’ ${messageId}`);
                } catch (redisError) {
                    console.error(`[${getTimestamp()}] âš ï¸  Failed to store alert mapping:`, redisError.message);
                    // Non-critical error - delete will still work if message is recent
                }
            }

            console.log(`[${getTimestamp()}] âœ… Bullying alert sent to admin for ${groupName}`);
            console.log(`[${getTimestamp()}] ğŸ“Š Severity: ${severity}, Matched: ${matchedWords.length} words`);
            console.log(`[${getTimestamp()}] ğŸ“ Real phone: ${realPhone}`);

            return true;
        } catch (error) {
            console.error(`[${getTimestamp()}] âŒ Failed to send bullying alert:`, error.message);
            return false;
        }
    }

    /**
     * Log offensive content detection (for audit purposes)
     * @param {object} data - Detection data
     */
    logDetection(data) {
        const { groupName, senderPhone, matchedWords, severity } = data;

        console.log(`[${getTimestamp()}] ğŸš¨ OFFENSIVE CONTENT DETECTED`);
        console.log(`   Group: ${groupName}`);
        console.log(`   User: ${senderPhone}`);
        console.log(`   Severity: ${severity}`);
        console.log(`   Matched: ${matchedWords.length} words (${matchedWords.join(', ')})`);
    }

    /**
     * Get monitoring statistics
     * @returns {object} Service statistics
     */
    getStats() {
        return {
            totalWords: ALL_OFFENSIVE_WORDS.length,
            adminPhone: this.adminPhone,
            enabled: true
        };
    }
}

// Export singleton instance
module.exports = new BullyingMonitoringService();
